{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df20ae58",
   "metadata": {},
   "source": [
    "## Acknowledge example\n",
    "This notebook shows the main workflow for the article. This should be easily replicated with your own data files. Simply replace the path_to_file variable with a path to your own file to read into pandas. You can then follow the steps as they are. The article goes more in depth into the motivation for these methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6982614",
   "metadata": {},
   "outputs": [],
   "source": [
    "from acknowledge.acknowledge import few_shot, instruction\n",
    "from acknowledge.completions import *\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import json\n",
    "#for nicer df display\n",
    "from IPython.display import display, HTML\n",
    "#simple data exploration\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae68019",
   "metadata": {},
   "source": [
    "### Loading data\n",
    "The article and this example use Web of Science data. Depending on how you download it, the funding text column could be named differently. You can also use it for other data, just make sure you are using the right column names for the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59eabafa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1482, 92)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load csv into pandas\n",
    "path_to_file='path-to-file.csv'\n",
    "\n",
    "df = pd.read_csv(path_to_file)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14fa1723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Funding Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We thank ESRF for the synchrotron radiation be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Financial support from the European Union with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We gratefully acknowledge the ESRF for grantin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K.C. benefited from support of the Deutsche Fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This work was supported by the U.S. National S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Funding Text\n",
       "0  We thank ESRF for the synchrotron radiation be...\n",
       "1  Financial support from the European Union with...\n",
       "2  We gratefully acknowledge the ESRF for grantin...\n",
       "3  K.C. benefited from support of the Deutsche Fo...\n",
       "4  This work was supported by the U.S. National S..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the texts to extract\n",
    "df[['Funding Text']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d96c89f",
   "metadata": {},
   "source": [
    "### Few shot and instruction methods\n",
    "Both methods use the same keys (see below). The difference is how we prompt the models. \n",
    "1. The few shot method maps three examples of prompts and completions to teach the model what to extract.\n",
    "2. The instruction method simply tells the model what to do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10277146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'funding agencies (FUND), grant numbers (GRNB), facilities or universities or labs (INFRA), beamlines (BEAM), individuals with full names (IND), and type of assistance (TYPE)'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#keys/information to extract from text\n",
    "keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a662ed",
   "metadata": {},
   "source": [
    "### Few-shot learning\n",
    "Maps three examples of prompt to completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "423f2245",
   "metadata": {},
   "outputs": [],
   "source": [
    "#few_shot module\n",
    "few_shot??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c105f88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Open Access funding provided by Projekt DEAL. The authors gratefully acknowledge the support of Dr. Olaf Medenbach for performing the pre-preparation and Mr. Maximilian Kruth, Forschungszentrum Julich, Ernst Ruska-Centre for Microscopy and Spectroscopy with Electrons (ER-C) for the fine-tuning of the SXNT sample. The authors would like to thank Dr. Robert Mucke, Forschungszentrum Julich, Institute of Energy and Climate Research: Materials Synthesis and Processing (IEK-1) for the data management and assisting with the analyses of the tomograms. We gratefully acknowledge the German Federal Ministry of Education and Research (BMBF) for financing of the project Verbundvorhaben SOFC Degradation (Proposal Number 03SF0494A) and the ESRF for its financial support under MA-3254 experiment at the ID16B beamline.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#completions used for few_shot method, see prompt_2, prompt_3 with their completions for more examples\n",
    "prompt_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d4a5642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FUND': 'Projekt DEAL|German Federal Ministry of Education and Research (BMBF)|ESRF',\n",
       " 'IND': 'Dr. Olaf Medenbach|Mr. Maximilian Kruth|Dr. Robert Mucke',\n",
       " 'INFRA': 'Forschungszentrum Julich|Ernst Ruska-Centre for Microscopy and Spectroscopy with Electrons (ER-C)|Institute of Energy and Climate Research: Materials Synthesis and Processing (IEK-1)',\n",
       " 'BEAM': 'ID16B',\n",
       " 'GRNB': '03SF0494A',\n",
       " 'TYPE': 'open access funding|performing preparation|fine-tuning of the SXNT sample|data management and assisting with analysis|financing the project|financial support'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_1# expected completion from prompt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9fbe467",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt='\\n\\n\\n[Keys]:{}\\n\\n\\n[Text1]:{}\\n\\n[Output1]:{}\\n\\n[Text2]:{}\\n\\n[Output2]:{}\\n\\n[Text3]:{}\\n\\n[Output3]:{}\\n\\n[Text4]:{}\\n\\n[Output4]:'.format(\n",
    "                          keys, #keys  \n",
    "                          prompt_1,#trainx_1  \n",
    "                          json.dumps(completion_1),#trainy_1  \n",
    "                          prompt_2, #trainx_2  \n",
    "                          json.dumps(completion_2), #trainy_2  \n",
    "                          prompt_3, #trainx_3   \n",
    "                          json.dumps(completion_3), #trainy_3  \n",
    "                          '[NEW_PROMPT]'#testx_i  \n",
    "            )\n",
    "#print(prompt) #uncomment to see how the model takes in this prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4945909d",
   "metadata": {},
   "source": [
    "### Instruction (or Instruct)\n",
    "Gives the prompt in the form of an instruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "acddeca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instruction module\n",
    "instruction??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "151009d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Extract the following data: funding agencies (FUND), grant numbers (GRNB), facilities or universities or labs (INFRA), beamlines (BEAM), individuals with full names (IND), and type of assistance (TYPE) in JSON format, use \"NaN\" if none found. From the following text: [NEW_PROMPT]'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instructions for instruction module\n",
    "instructions + '[NEW_PROMPT]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cf9f2a",
   "metadata": {},
   "source": [
    "### Running the model\n",
    "The preliminary evaluation in the article found that **fsl** with **gpt-3.5-turbo** was the most accurate version and are thus the **default**. It is also cheaper to run that InstructGPT. GPT-4 came out while finalising this article. Limited testing with fsl showed no obvious signs of improvement. However, it is possible that it will perform better with instructions.\n",
    "\n",
    "#### Checkpoints\n",
    "This script implements checkpoints with pickle. If stopped or interrupted somehow, simply re-run the block to resume with the data structuring/processing. The file is saved in the checkpoints folder and the name will be constructed based on model and method name, as well as a prefix you can add below. \"checkpoint name\" + \"model version\" + \"method\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6dadb73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gpt-3.5-turbo with the following parameters:\n",
      "max_tokens=500\n",
      "stop=\n",
      "\n",
      "[Output]:\n",
      "temperature=0\n",
      "Dataset has 1482 rows and 141488 words\n",
      "Resuming from checkpoint\n",
      "Saving to v2_gpt-3.5-turbo_fsl.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished!'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#runs the model, saves error list and index if any (only available for few_shot with gpt-3.5-)\n",
    "# other model options 'text-davinci-003', 'gpt-3.5-turbo', 'ada', 'gpt-4'\n",
    "#to run with instruction method, simply change the function name to instruction, or use the block below\n",
    "\n",
    "few_shot(#using few_shot\n",
    "    df, #pandas dataframe\n",
    "    'Funding Text', #column name with text \n",
    "    checkpoint_name='v2', #name for your checkpoint\n",
    "    model='gpt-3.5-turbo', #model version to use\n",
    "    delay=0 #delay in seconds between texts\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accba685",
   "metadata": {},
   "source": [
    "The script tells you the checkpoint name: \"Saving to v2_gpt-3.5-turbo_fsl.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f2258632",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to run with instruction method, simply uncomment below\n",
    "\n",
    "#instruction(#using instruction\n",
    "#    df, #pandas dataframe\n",
    "#    'Funding Text', #column name with text \n",
    "#    checkpoint_name='v2', #name for your checkpoint\n",
    "#    model='gpt-3.5-turbo', #model version to use\n",
    "#    delay=0 #delay in seconds between texts\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cdfb020e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for errors again\n",
    "path_errors='errors/error_list.pickle'\n",
    "\n",
    "with open(path_errors, 'rb') as f:\n",
    "    error_list = pickle.load(f)\n",
    "error_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbee938",
   "metadata": {},
   "source": [
    "### Inspecting data\n",
    "Load the checkpoint with pickle to inspect data, you can just copy and paste the checkpoint name below, making sure you are directing the path to the checkpoints folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d57ae4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loads checkpoint in pickle format\n",
    "\n",
    "path_to_checkpoint = 'checkpoints/#your-checkpoint-here#'\n",
    "\n",
    "with open(path_to_checkpoint, 'rb') as f:\n",
    "    checkpoint = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ebdcf7",
   "metadata": {},
   "source": [
    "The texts have been structured into 6 columns, based on the keys provided to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37bdf44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1482, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FUND</th>\n",
       "      <th>IND</th>\n",
       "      <th>INFRA</th>\n",
       "      <th>BEAM</th>\n",
       "      <th>GRNB</th>\n",
       "      <th>TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>French Research Agency|German Science Foundati...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ESRF</td>\n",
       "      <td>synchrotron radiation</td>\n",
       "      <td>ANR-14-CE35-0028-01|DFG Ta259/12|NANOTRANSMED|...</td>\n",
       "      <td>acknowledgement of support|fellowship|PhD fell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>European Union NFFA|Helmholtz Associations Ini...</td>\n",
       "      <td>PT-DESY</td>\n",
       "      <td></td>\n",
       "      <td>FIB dual beam</td>\n",
       "      <td>NFFA 654360|5K13WC3|18-41-06001</td>\n",
       "      <td>financial support|use of instrument|support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Russian Science Foundation</td>\n",
       "      <td>Patrick Merz|Horst Bormann|Gohil Takur</td>\n",
       "      <td>ESRF|Nuclear Resonance beamline ID18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17-72-20200|HC-2440</td>\n",
       "      <td>granting beam time|synthesizing &lt;SUP&gt;57&lt;/SUP&gt;F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deutsche Forschungsgemeinschaft (DFG)|Max Plan...</td>\n",
       "      <td>K.C.</td>\n",
       "      <td>SOLEIL|ESRF|NSRRC</td>\n",
       "      <td>synchrotron</td>\n",
       "      <td>SE 1441/1-2|SFB 1143 (project-id 247310070)|Gr...</td>\n",
       "      <td>benefited from support|partially supported|gra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U.S. National Science Foundation|U.S. Departme...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Advanced Photon Source|Argonne National Labora...</td>\n",
       "      <td>x-ray microdiffraction</td>\n",
       "      <td>DMR-1609545|NaN|51802057|DD45001017|2016YFA030...</td>\n",
       "      <td>financial support|development of instrumentati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                FUND  \\\n",
       "0  French Research Agency|German Science Foundati...   \n",
       "1  European Union NFFA|Helmholtz Associations Ini...   \n",
       "2                         Russian Science Foundation   \n",
       "3  Deutsche Forschungsgemeinschaft (DFG)|Max Plan...   \n",
       "4  U.S. National Science Foundation|U.S. Departme...   \n",
       "\n",
       "                                      IND  \\\n",
       "0                                     NaN   \n",
       "1                                 PT-DESY   \n",
       "2  Patrick Merz|Horst Bormann|Gohil Takur   \n",
       "3                                    K.C.   \n",
       "4                                     NaN   \n",
       "\n",
       "                                               INFRA                    BEAM  \\\n",
       "0                                               ESRF   synchrotron radiation   \n",
       "1                                                              FIB dual beam   \n",
       "2               ESRF|Nuclear Resonance beamline ID18                     NaN   \n",
       "3                                  SOLEIL|ESRF|NSRRC             synchrotron   \n",
       "4  Advanced Photon Source|Argonne National Labora...  x-ray microdiffraction   \n",
       "\n",
       "                                                GRNB  \\\n",
       "0  ANR-14-CE35-0028-01|DFG Ta259/12|NANOTRANSMED|...   \n",
       "1                    NFFA 654360|5K13WC3|18-41-06001   \n",
       "2                                17-72-20200|HC-2440   \n",
       "3  SE 1441/1-2|SFB 1143 (project-id 247310070)|Gr...   \n",
       "4  DMR-1609545|NaN|51802057|DD45001017|2016YFA030...   \n",
       "\n",
       "                                                TYPE  \n",
       "0  acknowledgement of support|fellowship|PhD fell...  \n",
       "1        financial support|use of instrument|support  \n",
       "2  granting beam time|synthesizing <SUP>57</SUP>F...  \n",
       "3  benefited from support|partially supported|gra...  \n",
       "4  financial support|development of instrumentati...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#structured acknowledgements data\n",
    "acknowledge = pd.DataFrame(checkpoint)\n",
    "print(acknowledge.shape)\n",
    "acknowledge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d353ad54",
   "metadata": {},
   "source": [
    "An example of the first text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd93b040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We thank ESRF for the synchrotron radiation beam time. We thank the French Research Agency (grant ANR-14-CE35-0028-01 to M.P.K.), the German Science Foundation (DFG Ta259/12 to M.T.), the INTERREG V Upper Rhine Program (NANOTRANSMED to M.P.K. and M.T.), and the Japan Society for the Promotion of Science (16K05515 to A.Y.). M.V. thanks DFG (GRK1114, EcTop2) for the fellowship. S.M. is thankful to Konrad-Adenauer Foundation and X.L. thanks ANR for PhD fellowships. W.A. thanks the Alexander von Humboldt Foundation. M.T. thanks Nakatani Foundation for support.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example, original text\n",
    "df[['Funding Text']].iloc[0].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b800f22",
   "metadata": {},
   "source": [
    "The following is extracted and structured into tabular data, with a pipe separator and no spaces, like so: a|b|c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1e42c44f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FUND</th>\n",
       "      <th>IND</th>\n",
       "      <th>INFRA</th>\n",
       "      <th>BEAM</th>\n",
       "      <th>GRNB</th>\n",
       "      <th>TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>French Research Agency|German Science Foundation|INTERREG V Upper Rhine Program|Japan Society for the Promotion of Science|DFG (GRK1114, EcTop2)|Konrad-Adenauer Foundation|Alexander von Humboldt Foundation|Nakatani Foundation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ESRF</td>\n",
       "      <td>synchrotron radiation</td>\n",
       "      <td>ANR-14-CE35-0028-01|DFG Ta259/12|NANOTRANSMED|16K05515</td>\n",
       "      <td>acknowledgement of support|fellowship|PhD fellowships</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#extracts following table\n",
    "display(HTML(acknowledge.iloc[[0]].to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f93f0c7",
   "metadata": {},
   "source": [
    "It can be further processed and explored. Below, the most common types of acknowledgements are explored. This can be changed to any column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "979cfbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TYPE: 5726 observations\n",
      "2588 are unique\n",
      "\n",
      "...of which, the top 10 are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "financial support               668\n",
       "support                         391\n",
       "funding                         338\n",
       "NaN                             135\n",
       "technical support                52\n",
       "technical assistance             49\n",
       "fruitful discussions             42\n",
       "acknowledgement                  37\n",
       "research support                 37\n",
       "assistance in using beamline     37\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column='TYPE' #change column name here\n",
    "n=10 #top n to see below\n",
    "\n",
    "x_list=[]\n",
    "for i in acknowledge.index:\n",
    "    x_list.append(acknowledge[column].str.split('|')[i])\n",
    "x_list = list(chain(*x_list))\n",
    "\n",
    "sample = pd.Series(x_list)\n",
    "\n",
    "print('{}: {} observations'.format(column, sample.shape[0]))\n",
    "print('{} are unique'.format(len(sample.unique())))\n",
    "print('\\n...of which, the top {} are:'.format(n))\n",
    "sample.value_counts().head(n) # showing top 10 results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
